{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lusidtools.jupyter_tools import toggle_code\n",
    "\n",
    "\"\"\"Structured Results Store for storage of Portfolio data\n",
    "\n",
    "Attributes\n",
    "----------\n",
    "structured_results_store\n",
    "virtual_document\n",
    "luminesce\n",
    "\"\"\"\n",
    "\n",
    "toggle_code(\"Toggle Docstring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b0dba",
   "metadata": {},
   "source": [
    "# Structured Results Store Example\n",
    "\n",
    "This notebook demostrates loading of a custom Portfolio dataset into the LUSID Structured Results Store.\n",
    "\n",
    "For more context on what a Structure Result Store/Data is see KB Article <a ref=https://support.lusid.com/knowledgebase/article/KA-01893/en-us>KA-01893</a>\n",
    "\n",
    "Once loaded, the dataset can be retrieved as one document, or the individual fields accessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50382822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import io\n",
    "import json\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain\n",
    "\n",
    "# Then import the key modules from the LUSID package (i.e. The LUSID SDK)\n",
    "import lusid as lu\n",
    "import lusid.models as lm\n",
    "from lusidjam import RefreshingToken\n",
    "\n",
    "# And use absolute imports to import key functions from Lusid-Python-Tools and other helper package\n",
    "from lusid.utilities import ApiClientFactory\n",
    "\n",
    "# Set DataFrame display formats\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# Authenticate our user and create our API client\n",
    "secrets_path = os.getenv(\"FBN_SECRETS_PATH\")\n",
    "\n",
    "api_factory = ApiClientFactory(\n",
    "    token=RefreshingToken(),\n",
    "    api_secrets_filename=secrets_path,\n",
    "    app_name=\"LusidJupyterNotebook\",\n",
    ")\n",
    "\n",
    "api_status = pd.DataFrame(\n",
    "    api_factory.build(lu.ApplicationMetadataApi).get_lusid_versions().to_dict()\n",
    ")\n",
    "\n",
    "display(api_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d415a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "srs_api = api_factory.build(lu.StructuredResultDataApi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7e2694",
   "metadata": {},
   "source": [
    "<h2>Scope, Effective Date, Result Type</h2>\n",
    "\n",
    "<ul>\n",
    "<li>Scope: The scope in which to create or update data maps.</li>\n",
    "<li>Effective Date: Date at which the structured result is effective from.</li>\n",
    "<li>Result Type: The Class of the Result, has to be one of [UnitResult/Analytic, UnitResult/Grouped, UnitResult/Holding]</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71284305",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = \"srs\" \n",
    "effective_date = datetime(2021, 1, 27, tzinfo=timezone.utc)\n",
    "sample_data_result_type = \"UnitResult/Custom\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15535c",
   "metadata": {},
   "source": [
    "## Define functions to create the Data Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f54a36",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Data Mapping</h3>\n",
    "\n",
    "The Structured Result Store allows us to upsert structured results, but to give them structure we must first define a Data Mapping,\n",
    "\n",
    "You can think of a Data Mapping as defining the columns and the column types for each row that gets upserted into the SRS using a specific Data Map\n",
    "\n",
    "Each \"row\" can have multiple keys and when difining the data map there are 4 different key types, Unique, PartOfUnique, Leaf, and CompositeLeaf\n",
    "\n",
    "<h4>Unique</h4>\n",
    "<blockquote>A primary key that will throw a unique key constraint if multiple equal values are upserted for a single specific result type</blockquote>\n",
    "<h4>Part of Unique</h4>\n",
    "<blockquote>A key that will be considered as part of the compoisite primary key for an entity</blockquote>\n",
    "<h4>Leaf</h4>\n",
    "<blockquote>Leaf define a value that wont be considered as part of the primary or primary composite key.</blockquote>\n",
    "<h4>Composite Leaf</h4>\n",
    "<blockquote>\n",
    "CompositeLeaf is an abstraction that allows the user to specify which Leafs should be connected, they define data types rather than names of entities as they represent a group of entities.\n",
    "E.g. If we have an Accural we can define a composite leaf as two leafs of amount and currency\n",
    "<p></p>\n",
    "<blockquote>\n",
    "\"UnitResult/Accrual\"\n",
    "\n",
    "DataDefinition(address=\"UnitResult/Accrual\", dataType= \"Result0D\", keyType=\"CompositeLeaf\") \n",
    "</blockquote>\n",
    "\n",
    "<blockquote>\n",
    "\"UnitResult/Accrual/Amount\"\n",
    "\n",
    "DataDefinition(address=\"UnitResult/Accrual/Amount\", name=\"Accrual\", dataType= \"decimal\", keyType=\"Leaf\")\n",
    "</blockquote>\n",
    "<blockquote>\n",
    "\"UnitResult/Accrual/Ccy\"\n",
    "\n",
    "DataDefinition(address=\"UnitResult/Accrual/AmountCcy\", name=\"AccrualCcy\", dataType= \"string\", keyType=\"Leaf\")\n",
    "</blockquote>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_srs_data_map(leaf_columns, unique_columns, data_types):\n",
    "    def define_data_definitions(columns, key_type):\n",
    "        return [lm.DataDefinition(address=f\"UnitResult/{scope}/{column}\", name=column, data_type=data_types[column], key_type=key_type) \n",
    "                      for column in columns]\n",
    "    data_map = [define_data_definitions(columns, key_type) for columns, key_type in zip((leaf_columns, unique_columns), (\"Leaf\", \"PartOfUnique\"))]\n",
    "\n",
    "    return lm.DataMapping(data_definitions = list(chain(*data_map)))\n",
    "\n",
    "def create_data_map(df, code, version, leaf_columns, unique_columns, data_types):\n",
    "    srs_data_map = gen_srs_data_map(leaf_columns, unique_columns, data_types)\n",
    "    srs_data_map_key = lm.DataMapKey(version=version, code=code)\n",
    "    \n",
    "    try:    \n",
    "        srs_api.create_data_map(\n",
    "            scope=scope, \n",
    "            request_body={\n",
    "                code: lm.CreateDataMapRequest(\n",
    "                    id = srs_data_map_key,\n",
    "                    data = srs_data_map\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "    except lu.ApiException as e:\n",
    "        detail = json.loads(e.body)\n",
    "        if detail['code'] not in [461]: \n",
    "            raise e\n",
    "    return srs_data_map_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac39670",
   "metadata": {},
   "source": [
    "## Read in sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/srs_custom_data.csv\")\n",
    "df = df.round(0)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081660b",
   "metadata": {},
   "source": [
    "## Upsert data into the Structured Results Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_and_load_data(dataFrame):\n",
    "    srs_ids=[]\n",
    "    \n",
    "    version = \"1.01\"\n",
    "    portfolios = dataFrame.groupby(\"Port\")\n",
    "    unique_columns = [\"Currency\", \"Date\", \"Sys\", \"Class\"]\n",
    "    leaf_columns = [column for column in dataFrame.columns if column not in unique_columns]\n",
    "    \n",
    "    sample_data_map_key = create_data_map(\n",
    "        df = df,\n",
    "        code = 'sample_data_map',\n",
    "        version = \"1.03\",\n",
    "        leaf_columns = leaf_columns,\n",
    "        unique_columns = unique_columns,\n",
    "        data_types = { \"RowId\": \"string\", \n",
    "                       \"Port\": \"string\",\n",
    "                       \"Currency\": \"string\",\n",
    "                       \"Date\": \"string\",\n",
    "                       \"Sys\": \"string\",\n",
    "                       \"Weight\": \"decimal\",\n",
    "                       \"Amount\": \"decimal\",\n",
    "                       \"Class\": \"string\"}\n",
    "    )\n",
    "\n",
    "    for portfolio_id, pf_df in portfolios:    \n",
    "        srs_id = lm.StructuredResultDataId(\n",
    "            source = \"Client\", \n",
    "            code = portfolio_id, \n",
    "            effective_at = effective_date,\n",
    "            result_type = sample_data_result_type)\n",
    "    \n",
    "        srs_ids.append(srs_id) \n",
    "    \n",
    "        csv_data = io.StringIO()\n",
    "        pf_df.to_csv(csv_data)   \n",
    "        \n",
    "        request_body = {\n",
    "            portfolio_id: lm.UpsertStructuredResultDataRequest(\n",
    "                id = srs_id,\n",
    "                data = lm.StructuredResultData(\n",
    "                    document_format = \"csv\",\n",
    "                    version = version,\n",
    "                    name = \"Data file\",\n",
    "                    document = csv_data.getvalue(),\n",
    "                    data_map_key = sample_data_map_key\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        result = srs_api.upsert_structured_result_data(\n",
    "            scope=scope,\n",
    "            request_body=request_body)\n",
    "\n",
    "        display(pd.DataFrame(result.values.items()))\n",
    "        \n",
    "    return srs_ids\n",
    "\n",
    "\n",
    "srs_ids = insert_and_load_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b606dcde",
   "metadata": {},
   "source": [
    "## Retrieve the raw data from the Structured Results Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data():\n",
    "    portfolio_ids = df['Port'].unique()\n",
    "\n",
    "    for portfolio_id in portfolio_ids:\n",
    "        srs_id = lm.StructuredResultDataId(\n",
    "            source = \"Client\", \n",
    "            code = portfolio_id, \n",
    "            effective_at = effective_date,\n",
    "            result_type = sample_data_result_type)\n",
    "        \n",
    "        result = srs_api.get_structured_result_data(\n",
    "            scope = scope, \n",
    "            request_body = {\n",
    "                \"key\": srs_id\n",
    "            }\n",
    "        )\n",
    "    \n",
    "        csv_data = io.StringIO(result.values[\"key\"].document)\n",
    "        doc = pd.read_csv(csv_data)\n",
    "        display(srs_id.code)\n",
    "        display(doc)\n",
    "        \n",
    "retrieve_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d58de",
   "metadata": {},
   "source": [
    "## Extract a 'Virtual Document' from the Structured Results Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71723d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_virtual_document():\n",
    "    portfolio_ids = df['Port'].unique()\n",
    "\n",
    "    for portfolio_id in portfolio_ids:\n",
    "        # Retrieve document from SRS\n",
    "        srs_id = lm.StructuredResultDataId(\n",
    "            source = \"Client\", \n",
    "            code = portfolio_id, \n",
    "            effective_at = effective_date,\n",
    "            result_type = sample_data_result_type)\n",
    "        \n",
    "        result = srs_api.get_virtual_document(\n",
    "            scope = scope, \n",
    "            request_body = {\n",
    "                \"key\": srs_id\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        result_dfs = []\n",
    "\n",
    "        for item in result.values[\"key\"].data:\n",
    "            columns = item.row_data.columns\n",
    "            values = [i.value for i in item.row_data.values]\n",
    "    \n",
    "            row_df = pd.DataFrame(values).T\n",
    "            row_df.columns = columns\n",
    "            \n",
    "            for row in item.row_id.items():            \n",
    "                row_df[row[0]] = [row[1]]\n",
    "\n",
    "            result_dfs.append(row_df)\n",
    "    \n",
    "        all_dfs = pd.concat(result_dfs)\n",
    "        \n",
    "        return all_dfs\n",
    "        \n",
    "all_dfs = retrieve_virtual_document()\n",
    "\n",
    "all_dfs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b13b1",
   "metadata": {},
   "source": [
    "<h2>Using Luminecese to access data in the Structured Result Store</h2>\n",
    "\n",
    "To access data in the SRS via luminecese we use the Lusid.UnitResult.AtomisedResult provider which takes a scope, code, source, resultType, and effectiveAt and asAt parameters are mandatory values.\n",
    "\n",
    "<ul>\n",
    "<li>Scope will determine where to look for the document e.g UnitResult/scope/...</li>\n",
    "<li>Code + Source will uniquely define a document inside the specified scope</li>\n",
    "<li>ResultType indicates the type of document</li>\n",
    "<li>EffectiveAt and asAt are used to give time context to reterieving the document.</li>\n",
    "</ul>\n",
    "\n",
    "Its important to note that the SRS does not store information in a tabular form, and thus in order to massage it into tabular data we need to pass the result from the AtomisedResult provider through a pivot, to acheive this we use the Tools.Pivot provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5cc689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lumipy\n",
    "import luminesce\n",
    "from fbnsdkutilities import ApiClientFactory\n",
    "\n",
    "api_factory = ApiClientFactory(\n",
    "    luminesce,\n",
    "    #token=RefreshingToken(),\n",
    "    api_secrets_filename=secrets_path,\n",
    "    app_name=\"LusidJupyterNotebook\",\n",
    ")\n",
    "\n",
    "lumi_sql_exe_api = api_factory.build(luminesce.SqlExecutionApi)\n",
    "\n",
    "res = lumi_sql_exe_api.put_by_query_csv(body=\"\"\"\n",
    "-- lumipy \n",
    "@@effAt = select datetime('now');\n",
    "@portfolio_data = use Lusid.UnitResult.AtomisedResult with @@effAt\n",
    "  --scope=srs\n",
    "  --code=PortA\n",
    "  --source=Client\n",
    "  --resultType=UnitResult/Custom\n",
    "  --effectiveAt={@@effAt:s}\n",
    "  --asAt={@@effAt:s}\n",
    "  enduse;\n",
    "\n",
    "@input = SELECT * FROM @portfolio_data WHERE `UnitResult/srs/Currency`=='USD';\n",
    "\n",
    "\n",
    "@x =\n",
    "select \n",
    "    DataKey,\n",
    "    [UnitResult/srs/Class],\n",
    "    [UnitResult/srs/Currency],\n",
    "    [UnitResult/srs/Date],\n",
    "    [UnitResult/srs/Sys],\n",
    "    max(coalesce(ValueReal, ValueText)) as Value\n",
    "from\n",
    "    @input\n",
    "group by\n",
    "    1, 2, 3, 4, 5\n",
    "    ;\n",
    "\n",
    "@pivoted = \n",
    "use Tools.Pivot with @x\n",
    "--aggregateColumns=Value\n",
    "enduse;\n",
    "\n",
    "select * from @pivoted;\"\"\",\n",
    "query_name=\"query\",\n",
    "timeout_seconds=3600)\n",
    "\n",
    "buffer_result = io.StringIO(res)\n",
    "srs_client_filetered = pd.read_csv(buffer_result, encoding='utf-8')\n",
    "\n",
    "srs_client_filetered.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fef24e3",
   "metadata": {},
   "source": [
    "## Cleanup - delete the data from the Structured Results Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077622bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_data():\n",
    "    portfolio_ids = df['Port'].unique()\n",
    "\n",
    "    for portfolio_id in portfolio_ids:\n",
    "        # Retrieve document from SRS\n",
    "        srs_id = lm.StructuredResultDataId(\n",
    "            source = \"Client\", \n",
    "            code = portfolio_id, \n",
    "            effective_at = effective_date,\n",
    "            result_type = sample_data_result_type)\n",
    "        \n",
    "        result = srs_api.delete_structured_result_data(\n",
    "            scope = scope, \n",
    "            request_body = {\n",
    "                \"key\": srs_id\n",
    "            }\n",
    "        )\n",
    "\n",
    "delete_data()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e2fdb6824b58df245d8c0f69db6a91fea5662329742c5abc6a03ace099cccbe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('fbn-ci')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

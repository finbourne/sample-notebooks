{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lusidtools.jupyter_tools import toggle_code\n",
    "\n",
    "\"\"\"Valuation Debugging\n",
    "\n",
    "Attributes\n",
    "----------\n",
    "valuation\n",
    "transactions\n",
    "instruments\n",
    "recipes\n",
    "\"\"\"\n",
    "\n",
    "toggle_code(\"Hide docstring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valuation Analysis\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "- 1. [Overview](#1.-Overview)\n",
    "- 2. [Setup](#2.-Setup)\n",
    "- 3. [Load Data](#3.-Load-Data)\n",
    "   * [3.1 Portfolios](#3.1-Portfolios)\n",
    "   * [3.2 Instruments](#3.2-Instruments)\n",
    "   * [3.3 Transactions](#3.3-Transactions)   \n",
    "   * [3.4 Quotes](#3.4-Quotes)\n",
    "- 4. [Accrual Overrides](#4.-Accrual-Overrides)\n",
    "   * [4.1 Match instruments with LUIDs](#4.1-Match-Instruments-With-LUID)\n",
    "   * [4.2 Create Data Map](#4.2-Create-Data-Map)\n",
    "- 5. [Valuations](#5.-Valuations)\n",
    "   * [5.1 Valuation Recipe](#5.1-Valuation-Recipes)\n",
    "   * [5.2 Valuation Function](#5.2-Valuation-Function)\n",
    "   * [5.3 Valuation Analysis](#5.3-Valuation-Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview\n",
    "\n",
    "One of the key constructs in LUSID is that of a Recipe. Recipes are a set of instructions for the valuation engine to determine how pricing will be conducted as well as what data will be used in the process. With Recipes, we can define things like which pricing sources to use (including fallback sources), which pricing models to use for various instrument types and what sort of lookback window to apply for quotes if a given quote doesn't exist on our valuation date.\n",
    "\n",
    "Given the flexibility that Recipes provide around sourcing of market data, one of the things often required is the ability to see what is actually used during a valuation. For example, if a large quote lookback quote window is specified of say 10 days, one may wish to see if a quote was used that's older than a week. Additionally, if multiple quote sources are specified with a given precidence order, a user may want to see which source was used if the primary source had no quote available. Finally, for fixed income instruments a number of metrics can be calculated or read from an outside source and users may wish to know where these figures come from.\n",
    "\n",
    "In this Notebook, we'll look at several key valuation metrics that can help us gain relavent insights to address the above concerns. We'll look at things through the lense of an alternative asset portfolio: 'GlobalAlternatives'. This portfolio contains six positions in a variety of alternative investment funds across farmland, climate, infrastructure, and private credit. \n",
    "\n",
    "Importantly, our example uses two seperate pricing sources with several of the funds having intermitant quotes across the month of January. The portfolios look as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](img/AlternativeFundStructure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup\n",
    "\n",
    "We first initialize our various Python libraries, objects, and datasets required to construct our examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lusid specific packages\n",
    "# These are the core lusid packages for interacting with the API via Python\n",
    "import lusid\n",
    "import lusid.models as models\n",
    "import json\n",
    "import pytz\n",
    "import uuid\n",
    "import luminesce\n",
    "import lumipy\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.rrule import rrule, DAILY\n",
    "from lusid.utilities import ApiClientFactory\n",
    "from lusidjam.refreshing_token import RefreshingToken\n",
    "from flatten_json import flatten\n",
    "from fbnsdkutilities import ApiClientFactory\n",
    "import backoff\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import io\n",
    "\n",
    "# Set pandas dataframe display formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "\n",
    "# Authenticate our user and create our API client\n",
    "secrets_path = os.getenv(\"FBN_SECRETS_PATH\")\n",
    "\n",
    "# Initiate API Factorys which are client side objects for interacting with LUSID and Luminesce APIs\n",
    "api_factory = lusid.utilities.ApiClientFactory(\n",
    "    token=RefreshingToken(),\n",
    "    api_secrets_filename = secrets_path,\n",
    "    app_name=\"LusidJupyterNotebook\")\n",
    "\n",
    "lumi_api_factory = ApiClientFactory(\n",
    "    luminesce,\n",
    "    token=RefreshingToken(),\n",
    "    api_secrets_filename=secrets_path,\n",
    "    app_name=\"LusidJupyterNotebook\",\n",
    ")\n",
    "\n",
    "#Load LUSID API Components\n",
    "portfolio_api = api_factory.build(lusid.api.PortfoliosApi)\n",
    "properties_api = api_factory.build(lusid.api.PropertyDefinitionsApi)\n",
    "transaction_portfolio_api = api_factory.build(lusid.api.TransactionPortfoliosApi)\n",
    "instruments_api = api_factory.build(lusid.api.InstrumentsApi)\n",
    "quotes_api = api_factory.build(lusid.api.QuotesApi)\n",
    "configuration_recipe_api = api_factory.build(lusid.api.ConfigurationRecipeApi)\n",
    "system_configuration_api = api_factory.build(lusid.api.SystemConfigurationApi)\n",
    "aggregration_api = api_factory.build(lusid.api.AggregationApi)\n",
    "srs_api = api_factory.build(lusid.api.StructuredResultDataApi)\n",
    "lumi_sql_exe_api = lumi_api_factory.build(luminesce.SqlExecutionApi)\n",
    "\n",
    "# Set Global Scope\n",
    "global_scope = \"Valuation_Analysis_NB\"\n",
    "\n",
    "# Transaction Portfolios\n",
    "global_alt_portfolio_code = \"GlobalAlternatives\"\n",
    "global_credit_portfolio_code = \"GlobalCredit\"\n",
    "\n",
    "# Load Requisite Data\n",
    "transaction_data = pd.read_excel(\"data/valuation_manifest_data.xlsx\", sheet_name=\"transactions\")\n",
    "price_data = pd.read_excel(\"data/valuation_manifest_data.xlsx\", sheet_name=\"market_prices\")\n",
    "instrument_data = pd.read_excel(\"data/valuation_manifest_data.xlsx\", sheet_name=\"instruments\")\n",
    "bond_accrual_data = pd.read_excel(\"data/valuation_manifest_data.xlsx\", sheet_name=\"bond_accruals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data\n",
    "\n",
    "The 'valuation_manifest_data.xlsx' data file contains the requisite instrument definitions, transactions, and market quotes used in our example. \n",
    "\n",
    "### 3.1 Portfolios \n",
    "\n",
    "We first start by constructing our alternative asset portfolio 'GlobalAlternatives' and our fixed income portfolio 'GlobalCredit':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_portfolio(portfolio_code):\n",
    "    # Create our Transaction Portfolios\n",
    "    try:\n",
    "        transaction_portfolio_api.create_portfolio(\n",
    "            scope=global_scope,\n",
    "            create_transaction_portfolio_request=models.CreateTransactionPortfolioRequest(\n",
    "                display_name=portfolio_code,\n",
    "                code=portfolio_code,\n",
    "                base_currency=\"USD\",\n",
    "                created=\"2021-12-31\",\n",
    "                instrument_scopes=[global_scope]\n",
    "            ),\n",
    "        )\n",
    "        print(\"Portfolio: \" + portfolio_code + \" loaded!\")\n",
    "\n",
    "    except lusid.ApiException as e:\n",
    "        print(json.loads(e.body)[\"title\"])\n",
    "        \n",
    "create_portfolio(global_alt_portfolio_code)\n",
    "create_portfolio(global_credit_portfolio_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Instruments\n",
    "\n",
    "Here we will create the functions to create instruments for each instrument type in the data file.\n",
    "\n",
    "#### 3.2.1 Create Equity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_equity(data):\n",
    "          \n",
    "    client_internal = \"Instrument/default/ClientInternal\"\n",
    "    \n",
    "    equity = models.Equity(\n",
    "        instrument_type=\"Equity\",\n",
    "        dom_ccy=data[\"currency\"],\n",
    "    )\n",
    "\n",
    "    equity_definition = models.InstrumentDefinition(\n",
    "        name=data[\"name\"],\n",
    "        identifiers={\"ClientInternal\": models.InstrumentIdValue(data[\"client_internal\"])},\n",
    "        definition=equity,\n",
    "        properties=[]      \n",
    "    )\n",
    "\n",
    "    # upsert the instrument\n",
    "    upsert_request = {client_internal: equity_definition}\n",
    "    upsert_response = instruments_api.upsert_instruments(scope=global_scope, request_body=upsert_request)\n",
    "    equity_luid = upsert_response.values[client_internal].lusid_instrument_id\n",
    "    return (equity_luid,data[\"client_internal\"],data[\"currency\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Create Bond Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bond(data):\n",
    "\n",
    "    flow_conventions = models.FlowConventions(\n",
    "        currency=data[\"currency\"],\n",
    "        payment_frequency=data[\"payment_frequency\"],\n",
    "        roll_convention=data[\"roll_convention\"],\n",
    "        day_count_convention=data[\"day_count_convention\"],\n",
    "        payment_calendars=[],\n",
    "        reset_calendars=[],\n",
    "        settle_days=data[\"settle_days\"],\n",
    "        reset_days=data[\"reset_days\"]\n",
    "    )\n",
    "\n",
    "    bond = models.Bond(\n",
    "        start_date=data[\"start_date\"].date(),\n",
    "        maturity_date=data[\"maturity_date\"].date(),\n",
    "        dom_ccy=data[\"dom_ccy\"],\n",
    "        principal=data[\"principal\"],\n",
    "        coupon_rate=data[\"coupon_rate\"],\n",
    "        flow_conventions=flow_conventions,\n",
    "        identifiers={},\n",
    "        instrument_type=\"Bond\",   \n",
    "        calculation_type=\"Standard\",\n",
    "    )\n",
    "\n",
    "    # define the instrument to be upserted\n",
    "    bond_definition = models.InstrumentDefinition(\n",
    "        name=data[\"bond_name\"],\n",
    "        identifiers={\"ClientInternal\": models.InstrumentIdValue(row[\"client_internal\"])},\n",
    "        definition=bond,\n",
    "    )\n",
    "\n",
    "    # upsert the instrument\n",
    "    upsert_request = {row[\"bond_identifier\"]: bond_definition}\n",
    "    upsert_response = instruments_api.upsert_instruments(scope=global_scope,request_body=upsert_request)\n",
    "    bond_luid = upsert_response.values[row[\"bond_identifier\"]].lusid_instrument_id\n",
    "    return (bond_luid,data[\"client_internal\"],data[\"currency\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Create Simple Instrument Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_instrument(data):\n",
    "          \n",
    "    client_internal = \"Instrument/default/ClientInternal\"\n",
    "    \n",
    "    simple_instrument = models.SimpleInstrument(\n",
    "        instrument_type=\"SimpleInstrument\",\n",
    "        dom_ccy=data[\"currency\"],\n",
    "        asset_class=\"Credit\",\n",
    "        simple_instrument_type=data[\"instrument_classification\"]\n",
    "    )\n",
    "\n",
    "    simple_instrument_definition = models.InstrumentDefinition(\n",
    "        name=data[\"name\"],\n",
    "        identifiers={\"ClientInternal\": models.InstrumentIdValue(data[\"client_internal\"])},\n",
    "        definition=simple_instrument,\n",
    "        properties=[]      \n",
    "    )\n",
    "\n",
    "    # upsert the instrument\n",
    "    upsert_request = {client_internal: simple_instrument_definition}\n",
    "    upsert_response = instruments_api.upsert_instruments(scope=global_scope, request_body=upsert_request)\n",
    "    simple_instrument_luid = upsert_response.values[client_internal].lusid_instrument_id\n",
    "    return (simple_instrument_luid,data[\"client_internal\"],data[\"currency\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Create instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we call our functions to create instruments. We will also need to record the internal Lusid instrument IDs in order to use them later in the SRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Luids = []\n",
    "\n",
    "# Load instruments\n",
    "for index, row in instrument_data.iterrows():\n",
    "    \n",
    "    if row[\"instrument_type\"] == \"Equity\":\n",
    "        Luids.append(create_equity(row))\n",
    "    elif row[\"instrument_type\"] == \"Bond\":\n",
    "        Luids.append(create_bond(row))\n",
    "    else:\n",
    "        Luids.append(create_simple_instrument(row))\n",
    "        \n",
    "print (\"Instruments Upserted!\")\n",
    "\n",
    "LuidMap = pd.DataFrame(Luids,columns = ['LusidInstrumentId','client_internal','Currency'])\n",
    "\n",
    "LuidMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Transactions\n",
    "To construct our holdings, we load in a set of transaction data across our 2 portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transactions\n",
    "for index, row in transaction_data.iterrows():\n",
    "\n",
    "    primary_instrument_identifier = { \"Instrument/default/ClientInternal\": row[\"client_internal\"] }\n",
    "    \n",
    "    if isinstance(row[\"client_internal\"], float):\n",
    "        primary_instrument_identifier = { \"Instrument/default/Currency\": row[\"currency\"] }\n",
    "\n",
    "    upsert_transactions = transaction_portfolio_api.upsert_transactions(\n",
    "        scope=global_scope,\n",
    "        code=row[\"portfolio\"],\n",
    "        transaction_request=[\n",
    "            models.TransactionRequest(\n",
    "                transaction_id=row[\"txn_id\"],\n",
    "                type=row[\"txn_type\"],\n",
    "                instrument_identifiers=primary_instrument_identifier,\n",
    "                transaction_date=row[\"trade_date\"],\n",
    "                settlement_date=row[\"settle_date\"],\n",
    "                units=row[\"quantity\"],\n",
    "                transaction_price=models.TransactionPrice(\n",
    "                    price=row[\"txn_price\"], type=\"Price\"\n",
    "                ),\n",
    "                total_consideration=models.CurrencyAndAmount(\n",
    "                    amount=row[\"total_consideration\"], currency=row[\"currency\"]\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "print (\"Transactions Upserted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Quotes\n",
    "We now load in the relavent market prices for our valuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load market prices\n",
    "instrument_quotes = {\n",
    "    str(uuid.uuid4()): models.UpsertQuoteRequest(\n",
    "            quote_id=models.QuoteId(\n",
    "                quote_series_id=models.QuoteSeriesId(\n",
    "                    provider=\"Lusid\",\n",
    "                    instrument_id=price[\"id\"],\n",
    "                    instrument_id_type=price[\"id_type\"],\n",
    "                    quote_type=\"Price\",\n",
    "                    field=\"mid\",\n",
    "                    price_source=price[\"price_source\"],\n",
    "                ),\n",
    "                effective_at=price[\"date\"],\n",
    "            ),\n",
    "            metric_value=models.MetricValue(value=price[\"price\"], unit=price[\"currency\"]),\n",
    "            scale_factor=price[\"scale_factor\"]\n",
    "    )\n",
    "    for row, price in price_data.iterrows()\n",
    "}\n",
    "\n",
    "# Upsert the quotes into LUSID\n",
    "response = quotes_api.upsert_quotes(\n",
    "    scope=global_scope, request_body=instrument_quotes\n",
    ")\n",
    "\n",
    "print (\"Quotes Upserted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accrual Overrides\n",
    "\n",
    "In our GlobalCredit portfolio we have two Instrument types: Corporate bonds and ABS. LUSID is able to calculate accrual values for corporate bonds, but not ABS instruments. Here we will upload some bond accrual data from our data file for the instruments which LUSID can't calculate. To do this, we need to create a map for the data and then upload it as a structured result data store (SRS) document.\n",
    "\n",
    "### 4.1 Match Instruments With LUID\n",
    "\n",
    "To upload the SRS data we need to provide the LUSID internal ID (LUID) along with our accruals data. We can do this by using the LUID map we created when we upserted the instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accrual_srs = pd.merge(bond_accrual_data,LuidMap, how=\"left\", on=\"client_internal\")\n",
    "accrual_srs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create Data Map\n",
    "\n",
    "Before uploading the SRS data we need a way to map each column to a valid SRS address, so that it can be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map_key = models.DataMapKey(\n",
    "    code = \"sample-data-map\",\n",
    "    version = \"1.0.16\"\n",
    ")    \n",
    "\n",
    "def upsert_structured_result_data_map(data_map_key):\n",
    "    \n",
    "    try:\n",
    "        srs_api.create_data_map(\n",
    "            scope = global_scope,\n",
    "            request_body = {\n",
    "                \"data-map\": models.CreateDataMapRequest(\n",
    "                    id=data_map_key,\n",
    "                    data=models.DataMapping(\n",
    "                        data_definitions=[\n",
    "                            models.DataDefinition(address=\"UnitResult/LusidInstrumentId\", name=\"LusidInstrumentId\", data_type=\"String\", key_type=\"Unique\"),\n",
    "                            models.DataDefinition(address=\"UnitResult/Valuation/InstrumentAccrued\", data_type=\"Result0D\", key_type=\"CompositeLeaf\"),\n",
    "                            models.DataDefinition(address=\"UnitResult/Valuation/InstrumentAccrued/Amount\", name=\"accrued_interest\", data_type=\"Decimal\", key_type=\"Leaf\"),\n",
    "                            models.DataDefinition(address=\"UnitResult/Valuation/InstrumentAccrued/Ccy\", name=\"Currency\", data_type=\"String\", key_type=\"Leaf\"),\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "    except lusid.ApiException as e:\n",
    "        print(json.loads(e.body))\n",
    "    \n",
    "upsert_structured_result_data_map(data_map_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we upload SRS data for each effective date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs_ids = []\n",
    "\n",
    "for effective_at, srs_df in accrual_srs.groupby(\"date\"):\n",
    "    \n",
    "    srs_data_id = models.StructuredResultDataId(\n",
    "        source=\"Client\",\n",
    "        code=\"BondAccrual\",\n",
    "        effective_at=effective_at,\n",
    "        result_type = \"UnitResult/Analytic\"\n",
    "    )\n",
    "    \n",
    "    srs_ids.append(srs_data_id)\n",
    "    \n",
    "    s = io.StringIO()\n",
    "    srs_df.to_csv(s)\n",
    "    \n",
    "    srs_data = models.StructuredResultData(\n",
    "        document_format=\"Csv\",\n",
    "        version=\"0.1.1\",\n",
    "        name=\"Bond Accrual\",\n",
    "        data_map_key=data_map_key,\n",
    "        document=s.getvalue()        \n",
    "    )\n",
    "    \n",
    "    srs_api.upsert_structured_result_data(\n",
    "        scope=global_scope, \n",
    "        request_body={ \n",
    "            \"data\": models.UpsertStructuredResultDataRequest(\n",
    "                id=srs_data_id, \n",
    "                data=srs_data\n",
    "            )\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sid in srs_ids:\n",
    "    \n",
    "    key = f\"{sid.code}-{str(uuid.uuid4())}\"\n",
    "    \n",
    "    values = srs_api.get_structured_result_data(\n",
    "        scope=global_scope, \n",
    "        request_body={\n",
    "            key: sid\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    s = io.StringIO(values.values[key].document)\n",
    "    values_df = pd.read_csv(s)\n",
    "    \n",
    "    display(values_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Valuations\n",
    "\n",
    "Now that we have our data uploaded, we will perform valuations and do some analysis on the figures returned. First we will define the functions needed.\n",
    "\n",
    "## 5.1 Valuation Recipes\n",
    "\n",
    "First, in order to perform our valuations we need to create valuation recipes. Here we will create 2 valuation recipes with somme common attributes. Both recipes will:\n",
    "\n",
    "- Use prices from the month_end_accounting price source first if available, with a quote interval of 10 days.\n",
    "- Use prices from the market_vendor price source second, with a quote interval of 10 days.\n",
    "- Use the SimpleStatic pricing model for bonds.\n",
    "- Override calculated accrued interest values with ones in the SRS where available.\n",
    "\n",
    "The difference will be that one allows partially successful evaluations and the other does not. We will look at what that means later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create two different recipes doepending on the AllowPartiallySuccessfulEvaluation option\n",
    "def UpsertRecipe(recipe_code, allow_partial_results):\n",
    "    \n",
    "    pricing_options = {}             \n",
    "    \n",
    "    if allow_partial_results == True:\n",
    "        pricing_options={\"AllowPartiallySuccessfulEvaluation\": True}\n",
    "    \n",
    "    configuration_recipe = models.ConfigurationRecipe(\n",
    "        scope=global_scope,\n",
    "        code=recipe_code,\n",
    "        market=models.MarketContext(\n",
    "            market_rules=[\n",
    "                models.MarketDataKeyRule(\n",
    "                    key=\"Quote.ClientInternal.*\",\n",
    "                    supplier=\"Lusid\",\n",
    "                    data_scope=global_scope,\n",
    "                    quote_type=\"Price\",\n",
    "                    field=\"mid\",\n",
    "                    quote_interval=\"10D\",\n",
    "                    price_source='month_end_accounting',\n",
    "                ),\n",
    "                models.MarketDataKeyRule(\n",
    "                    key=\"Quote.ClientInternal.*\",\n",
    "                    supplier=\"Lusid\",\n",
    "                    data_scope=global_scope,\n",
    "                    quote_type=\"Price\",\n",
    "                    field=\"mid\",\n",
    "                    quote_interval=\"10D\",\n",
    "                    price_source='market_vendor',\n",
    "                ),                \n",
    "            ],\n",
    "            options=models.MarketOptions(\n",
    "                default_supplier=\"Lusid\",\n",
    "                default_instrument_code_type=\"ClientInternal\",\n",
    "                default_scope=global_scope,\n",
    "                attempt_to_infer_missing_fx=True             \n",
    "            ),\n",
    "        ),\n",
    "        pricing=models.PricingContext(\n",
    "            model_rules=[\n",
    "                models.VendorModelRule(\n",
    "                    supplier=\"Lusid\",\n",
    "                    model_name=\"SimpleStatic\",\n",
    "                    instrument_type=\"Bond\",\n",
    "                    parameters=\"{}\",\n",
    "                )\n",
    "             ],             \n",
    "            result_data_rules=[\n",
    "                 models.ResultDataKeyRule(\n",
    "                     resource_key=\"UnitResult/Valuation/InstrumentAccrued\",\n",
    "                     supplier=\"Client\",\n",
    "                     data_scope=global_scope,\n",
    "                     document_code=\"BondAccrual\",\n",
    "                     quote_interval=\"1D\",\n",
    "                     document_result_type=\"UnitResult/Analytic\",\n",
    "                     result_key_rule_type=\"ResultDataKeyRule\"\n",
    "                 )\n",
    "                ],\n",
    "            options=pricing_options\n",
    "        )\n",
    "    )\n",
    "\n",
    "    upsert_configuration_recipe_response = (\n",
    "        configuration_recipe_api.upsert_configuration_recipe(\n",
    "            upsert_recipe_request=models.UpsertRecipeRequest(\n",
    "                configuration_recipe=configuration_recipe\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print (f\"Recipe {recipe_code} Upserted!\")\n",
    "    \n",
    "UpsertRecipe(\"ValuationAnalysisRecipe\", False)\n",
    "UpsertRecipe(\"ValuationAnalysisRecipeWPartialResult\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Valuation Function\n",
    "\n",
    "Now we create a function to perform the valuation and load the results into a data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valuation(date, portfolio_code, recipe_code, metricsList):    \n",
    "    try:        \n",
    "        # Build and run valuation request\n",
    "        valuation_request = models.ValuationRequest(\n",
    "            recipe_id=models.ResourceId(scope=global_scope, code=recipe_code),\n",
    "            metrics=metricsList,\n",
    "            portfolio_entity_ids=[\n",
    "                models.PortfolioEntityId(scope=global_scope, code=portfolio_code)\n",
    "            ],\n",
    "            valuation_schedule=models.ValuationSchedule(effective_at=date),\n",
    "        )\n",
    "\n",
    "        val_response = aggregration_api.get_valuation(valuation_request=valuation_request)\n",
    "        val_data = val_response.data\n",
    "        vals_df = pd.DataFrame(val_data)\n",
    "        \n",
    "        return vals_df\n",
    "    \n",
    "    except lusid.ApiException as e:\n",
    "        print(json.loads(e.body)[\"errorDetails\"][0][\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Valuation Analysis\n",
    "\n",
    "### 5.3.1 Allow Partial Results\n",
    "\n",
    "For our first valuation, we would like to look at the Global Alternatives portfolio. Firstly let's do a month end valuation for the 31st January:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    metrics = [\n",
    "        models.AggregateSpec(f\"Instrument/default/Name\", \"Value\"),\n",
    "        models.AggregateSpec(f\"Valuation/PV\", \"Value\"),\n",
    "        models.AggregateSpec(f\"Quotes/Price/PriceSource\", \"Value\"),\n",
    "    ]\n",
    "\n",
    "get_valuation(\"2022-01-31T00:00:00Z\", \"GlobalAlternatives\", \"ValuationAnalysisRecipe\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That one worked fine but now we want to perform a valuation for a different date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_valuation(\"2022-01-29T00:00:00Z\", \"GlobalAlternatives\", \"ValuationAnalysisRecipe\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This valuation has run into an error and can't be performed. We would like to see results for the rows that did not return an error, so if we run it with our second recipe which allows a return with partial results we can see some figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_valuation(\"2022-01-29T00:00:00Z\", \"GlobalAlternatives\", \"ValuationAnalysisRecipeWPartialResult\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Quote Age\n",
    "\n",
    "Now we might want to check how reliable/stale our quotes are. for that we can call on the effective date of the quote by adding that address to the metrics list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    models.AggregateSpec(f\"Instrument/default/Name\", \"Value\"),\n",
    "    models.AggregateSpec(f\"Valuation/PV\", \"Value\"),\n",
    "    models.AggregateSpec(f\"Quotes/Price/PriceSource\", \"Value\"),\n",
    "    models.AggregateSpec(f\"Quotes/Price/EffectiveAt\", \"Value\")\n",
    "]\n",
    "\n",
    "get_valuation(\"2022-01-14T00:00:00Z\", \"GlobalAlternatives\", \"ValuationAnalysisRecipe\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want this in a more readable format, we can create a function to calculate the age of the quote compared to the given date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lusid_date(quote_date_str, valuation_date_str):\n",
    "    if quote_date_str is None:\n",
    "        return None\n",
    "    else:        \n",
    "        quote_date = datetime.strptime(quote_date_str.split('.')[0], \"%Y-%m-%dT%H:%M:%S\");\n",
    "        valuation_date = datetime.strptime(valuation_date_str.split('.')[0], \"%Y-%m-%dT%H:%M:%SZ\");\n",
    "        return valuation_date - quote_date\n",
    "\n",
    "eff_date = \"2022-01-14T00:00:00Z\"\n",
    "valuation = get_valuation(eff_date, \"GlobalAlternatives\", \"ValuationAnalysisRecipe\", metrics)\n",
    "\n",
    "valuation['Quote Age (in days)'] = valuation[\"Quotes/Price/EffectiveAt\"].apply(parse_lusid_date, args=(eff_date,))\n",
    "\n",
    "valuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Valuation Manifest\n",
    "Another tool which can be used to analyse valuations is the valuation manifest. The manifest is a body of information produced by each valuation that explains how the results of every call to the GetValuation API are generated. It can answer questions like ‘how were my market rules resolved?’ and ‘how many times did I access pricing data from a particular vendor for a particular instrument?’.\n",
    "\n",
    "To get the manifest, we need the request ID which gets returned when the valuation is run. We can create a new valuation function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valuation_with_req_id(date, portfolio_code, recipe_code, metricsList):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Build and run valuation request\n",
    "        valuation_request = models.ValuationRequest(\n",
    "            recipe_id=models.ResourceId(scope=global_scope, code=recipe_code),\n",
    "            metrics=metricsList,\n",
    "            portfolio_entity_ids=[\n",
    "                models.PortfolioEntityId(scope=global_scope, code=portfolio_code)\n",
    "            ],\n",
    "            valuation_schedule=models.ValuationSchedule(effective_at=date),\n",
    "        )\n",
    "\n",
    "        val_response = aggregration_api.get_valuation(valuation_request=valuation_request)\n",
    "        val_data = val_response.data\n",
    "        vals_df = pd.DataFrame(val_data)\n",
    "        \n",
    "        resp_id = val_response.links[0].href[-22:]\n",
    "        \n",
    "        return (resp_id,vals_df)\n",
    "    \n",
    "    except lusid.ApiException as e:\n",
    "        print(json.loads(e.body)[\"errorDetails\"][0][\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a function to retreive the valuation manifest. The manifest must be retreived using Luminesce, which can be accessed with the lumipy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to request the valuations manifest given a specific request ID and effective date \n",
    "\n",
    "@backoff.on_predicate(backoff.expo, lambda x: len(x.values) < 1, max_tries = 5)\n",
    "def get_val_manifest(req_id, eff_date):\n",
    "\n",
    "    res = lumi_sql_exe_api.put_by_query_csv(body=f\"\"\"\n",
    "    --lumipy\n",
    "    select * from Lusid.Logs.Valuations.Manifest \n",
    "    where UserRequestId = '{req_id}' and \n",
    "          EffectiveAt = #{eff_date}#   \n",
    "    \"\"\",\n",
    "    query_name=\"query\",\n",
    "    timeout_seconds=30)\n",
    "\n",
    "    return pd.read_csv(io.StringIO(res), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform a valuation and retrieve the manifest. The manifest shows us that price data was requested for each instrument for both the month_end_accounting and market_vendor price sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eff_date = \"2022-01-14T00:00:00Z\"\n",
    "\n",
    "valuation = get_valuation_with_req_id(eff_date, \"GlobalAlternatives\", \"ValuationAnalysisRecipeWPartialResult\", metrics)\n",
    "\n",
    "valuation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_val_manifest(valuation[0],eff_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pick one of the errors returned and drill down into the JsonMarketDataObject row, we can see that a quote was not found for that price source and date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_val_manifest(valuation[0],eff_date)[\"JsonMarketDataObject\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 Calculated vs SRS Data\n",
    "\n",
    "For the bonds in our GlobalCredit portfolio, we would like to display the accrued interest in the valuation. For the 3 corporate bond positions this can be calculated by Lusid however for the 2 ABS positions we will need to use the data we loaded into the SRS in section 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    models.AggregateSpec(f\"Instrument/default/Name\", \"Value\"),\n",
    "    models.AggregateSpec(f\"Valuation/PV\", \"Value\"),\n",
    "    models.AggregateSpec(f\"Valuation/Accrued\", \"Value\")\n",
    "]\n",
    "\n",
    "get_valuation(\"2022-01-28T00:00:00Z\", \"GlobalCredit\", \"ValuationAnalysisRecipeWPartialResult\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know whether the accrued value came from the SRS or not, we can explicitly request the value using the \"UnitResult\" address. If a value is returned then the SRS has been used, if not then it has been calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    models.AggregateSpec(\"Instrument/default/Name\", \"Value\"),\n",
    "    models.AggregateSpec(\"Valuation/PV\", \"Value\"),\n",
    "    models.AggregateSpec(\"Valuation/Accrued\", \"Value\"),\n",
    "    models.AggregateSpec(\"UnitResult/Valuation/InstrumentAccrued\", \"Value\")\n",
    "]\n",
    "\n",
    "valuation = get_valuation(\"2022-01-28T00:00:00Z\", \"GlobalCredit\", \"ValuationAnalysisRecipeWPartialResult\", metrics)#[\"Aggregation/Errors\"][0]\n",
    "\n",
    "valuation[\"Accrual Source\"] = np.where(valuation[\"UnitResult/Valuation/InstrumentAccrued\"].isnull(),\"Calculation\",\"SRS\")\n",
    "\n",
    "del valuation[\"UnitResult/Valuation/InstrumentAccrued\"]\n",
    "del valuation[\"Aggregation/Errors\"]\n",
    "\n",
    "valuation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
